{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-05 17:25:22.297771: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warp 1.0.2 initialized:\n",
      "   CUDA Toolkit 11.5, Driver 11.4\n",
      "   Devices:\n",
      "     \"cpu\"      : \"x86_64\"\n",
      "     \"cuda:0\"   : \"NVIDIA GeForce GTX 1050 Ti with Max-Q Design\" (4 GiB, sm_61, mempool enabled)\n",
      "   Kernel cache:\n",
      "     /home/jonathan/.cache/warp/1.0.2\n",
      "Mitsuba 3 Variant: llvm_ad_rgb\n"
     ]
    }
   ],
   "source": [
    "# project\n",
    "import os\n",
    "import sys \n",
    "project_dir = os.path.join(os.path.expanduser('~'), 'git', 'diffsim-sysid')\n",
    "sys.path.insert(1, project_dir)\n",
    "# math\n",
    "import numpy as np\n",
    "# optim\n",
    "import torch\n",
    "# physics\n",
    "import openmesh\n",
    "import warp as wp\n",
    "import warp.sim as wps\n",
    "# graphics\n",
    "from copy import deepcopy\n",
    "import drjit as dr\n",
    "import mitsuba as mi\n",
    "from mitsuba.scalar_rgb import Transform4f as mit\n",
    "# plots\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "from src.mpl_utils import set_fig_size, set_mpl_format\n",
    "# config\n",
    "from src.config import cfg\n",
    "# dataset\n",
    "from src.dataset import load_train_data\n",
    "from src.data.visualize import print_example\n",
    "\n",
    "\n",
    "# setup\n",
    "set_mpl_format()\n",
    "wp.init()\n",
    "mi.set_variant('llvm_ad_rgb')\n",
    "print(f'Mitsuba 3 Variant: {mi.variant()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA:\n",
      "  fps: 12\n",
      "  fpv: 24\n",
      "  height: 256\n",
      "  max_objs: 10\n",
      "  path: /home/jonathan/git/diffsim-sysid/data/sets/\n",
      "  set: movi_a\n",
      "  width: 256\n",
      "EVAL:\n",
      "  OUTPUT:\n",
      "    FN:\n",
      "      config: config.yaml\n",
      "      log: log.txt\n",
      "      pred: pred.csv\n",
      "    path: \n",
      "  PARAM:\n",
      "    DENSITY:\n",
      "      include: True\n",
      "      prior: 1.35\n",
      "    FRICTION:\n",
      "      include: True\n",
      "      prior: 0.5\n",
      "    RESTITUTION:\n",
      "      include: True\n",
      "      prior: 0.5\n",
      "SYS_ID:\n",
      "  GEOM:\n",
      "    include: True\n",
      "    spm: 100\n",
      "  OPTIM:\n",
      "    beta1: 0.9\n",
      "    beta2: 0.999\n",
      "    decay: 0.0\n",
      "    lr: 0.01\n",
      "    optim: adam\n",
      "  VIS:\n",
      "    include: True\n",
      "    spp: 4\n",
      "    weight: 1.0\n",
      "  iter: 4\n",
      "  rand: False\n"
     ]
    }
   ],
   "source": [
    "# fill in your directory set up here\n",
    "config_fp = os.path.join(project_dir, f'cfg/templates/comp-movi_a.yaml')\n",
    "cfg.merge_from_file(config_fp)\n",
    "cfg.DATA.path = os.path.join(project_dir, 'data/sets/')\n",
    "print(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You use TensorFlow DType <dtype: 'float32'> in tfds.features This will soon be deprecated in favor of NumPy DTypes. In the meantime it was converted to float32.\n",
      "WARNING:absl:You use TensorFlow DType <dtype: 'int32'> in tfds.features This will soon be deprecated in favor of NumPy DTypes. In the meantime it was converted to int32.\n",
      "WARNING:absl:You use TensorFlow DType <dtype: 'uint16'> in tfds.features This will soon be deprecated in favor of NumPy DTypes. In the meantime it was converted to uint16.\n",
      "WARNING:absl:You use TensorFlow DType <dtype: 'uint8'> in tfds.features This will soon be deprecated in favor of NumPy DTypes. In the meantime it was converted to uint8.\n",
      "2024-04-05 17:25:24.201864: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-05 17:25:24.203047: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-05 17:25:24.203332: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-05 17:25:24.204023: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-05 17:25:24.204789: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-05 17:25:24.205159: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-05 17:25:24.205393: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-05 17:25:25.419409: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-05 17:25:25.419621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-05 17:25:25.419788: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-05 17:25:25.419954: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 33 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050 Ti with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "2024-04-05 17:25:25.436207: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:735] failed to allocate 33.06M (34668544 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "WARNING:absl:`FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.\n",
      "WARNING:absl:`FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.\n",
      "WARNING:absl:`FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.\n",
      "WARNING:absl:`FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.\n",
      "WARNING:absl:`FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video: b'1680', Num objects: 8\n"
     ]
    }
   ],
   "source": [
    "train_ds, ds_info = load_train_data(cfg)\n",
    "sample = next(iter(train_ds))\n",
    "\n",
    "vid_id = sample['metadata']['video_name']\n",
    "obj_count = sample['metadata']['num_instances']\n",
    "print(f'Video: {vid_id}, Num objects: {obj_count}')\n",
    "# print_example(example, ds_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# camera positioned to view the scene, adjust as needed\n",
    "cam_pos = np.array([0.0, 1.0, 5.0])  \n",
    "cam_target = np.array([0.0, 1.0, 0.0])\n",
    "cam_up = np.array([0.0, 1.0, 0.0])\n",
    "\n",
    "# particle\n",
    "particle_init_pos = np.array([-0.5, 2.0, 0.0])\n",
    "particle_init_vel = np.array([0.0, 0.0, 0.0])\n",
    "particle_radius = 1.0\n",
    "particle_mass = 1.0\n",
    "particle_rgb = np.array([0.2, 0.25, 0.7])\n",
    "\n",
    "# target\n",
    "particle_target_vel = np.array([3.0, 0.0, 0.0])\n",
    "target_pos = np.array([0.7,  1.2114,  0.])\n",
    "\n",
    "# simulation parameters\n",
    "sim_duration = 0.4\n",
    "# control frequency\n",
    "fps = 60\n",
    "frame_dt = 1.0 / float(fps)\n",
    "frame_steps = int(sim_duration / frame_dt)\n",
    "# sim frequency\n",
    "sim_substeps = 8\n",
    "sim_steps = frame_steps * sim_substeps\n",
    "sim_dt = frame_dt / sim_substeps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Physics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_phys(device, est_names=[], pred_names=[]):\n",
    "    requires_grad = len(est_names) > 0\n",
    "    \n",
    "    builder = wps.ModelBuilder()\n",
    "    # particle\n",
    "    builder.add_particle(pos=particle_init_pos, vel=particle_init_vel, radius=particle_radius, mass=particle_mass)\n",
    "    model = builder.finalize(device, requires_grad=requires_grad)\n",
    "\n",
    "    # set up states\n",
    "    states = [model.state(requires_grad=requires_grad) for _ in range(sim_steps + 1)]\n",
    "\n",
    "    # params being estimated\n",
    "    est_params = {}\n",
    "    for name in est_names:\n",
    "        if name == 'vel':\n",
    "            est_params[name] = wp.to_torch(states[0].particle_qd)\n",
    "    \n",
    "    # params being predicted\n",
    "    pred_params = {}\n",
    "    for name in pred_names:\n",
    "        if name == 'pos':\n",
    "            pred_params[name] = wp.to_torch(states[-1].particle_q)\n",
    "            \n",
    "    return model, states, est_params, pred_params\n",
    "\n",
    "\n",
    "def capture_phys(device, model, integrator, states):\n",
    "    # tape tracks computation graph\n",
    "    tape = wp.Tape()\n",
    "    wp.capture_begin(device=device)\n",
    "    with tape:\n",
    "        for i in range(sim_steps):\n",
    "            states[i].clear_forces()\n",
    "            integrator.simulate(model, states[i], states[i + 1], sim_dt)\n",
    "    graph = wp.capture_end()\n",
    "\n",
    "    return graph, tape\n",
    "\n",
    "\n",
    "def get_trajectory(states):\n",
    "    trajectory = []\n",
    "    for state in states[::sim_substeps]:\n",
    "        trajectory.append(state.particle_q.numpy().squeeze())\n",
    "    return np.array(trajectory)\n",
    "\n",
    "\n",
    "def distance(target_pose, pred_pose):\n",
    "    return torch.linalg.norm(target_pose - pred_pose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rendering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = 256\n",
    "img_height = 256\n",
    "fov = 60\n",
    "\n",
    "render_integrator = {\n",
    "    'type': 'direct_reparam',\n",
    "}\n",
    "\n",
    "scene_dict = {\n",
    "    'type': 'scene',\n",
    "    'integrator': render_integrator,\n",
    "    'sensor':  {\n",
    "        'type': 'perspective',\n",
    "        'to_world': mit.look_at(\n",
    "                        origin=cam_pos,\n",
    "                        target=cam_target,\n",
    "                        up=cam_up),\n",
    "        'fov': fov,\n",
    "        'film': {\n",
    "            'type': 'hdrfilm',\n",
    "            'width': img_width,\n",
    "            'height': img_height,\n",
    "            'rfilter': { 'type': 'gaussian' },\n",
    "            'sample_border': True\n",
    "        },\n",
    "    },\n",
    "    \"light\": {\n",
    "        \"type\": \"constant\"\n",
    "    },\n",
    "    'particle': {\n",
    "        'type': 'sphere',\n",
    "        'center': particle_init_pos,\n",
    "        'radius': particle_radius,\n",
    "        'bsdf': {\n",
    "            'type': 'diffuse',\n",
    "            'reflectance': {\n",
    "                'type': 'rgb',\n",
    "                'value': particle_rgb\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"ground\": {\n",
    "        \"type\": \"rectangle\",\n",
    "        \"to_world\": mit.rotate(axis=[1.0, 0.0, 0.0], angle=-90).scale(20),\n",
    "        \"bsdf\": {\n",
    "            \"type\": \"diffuse\",\n",
    "            'reflectance': {\n",
    "                'type': 'checkerboard',\n",
    "                'to_uv': mi.ScalarTransform4f.scale([10, 10, 1])\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "target_scene_dict = dict(scene_dict)\n",
    "target_scene_dict['particle']['center'] = deepcopy(target_pos)\n",
    "target_img = mi.render(mi.load_dict(target_scene_dict), spp=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial run \n",
    "phys_device = wp.get_cuda_devices()[0]\n",
    "phys_model, phys_states, _, phys_pred = build_phys(phys_device, pred_names=['pos'])\n",
    "phys_integrator = wp.sim.SemiImplicitIntegrator()\n",
    "phys_graph, _ = capture_phys(phys_device, phys_model, phys_integrator, phys_states)\n",
    "wp.capture_launch(phys_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_size = set_fig_size(subplots=(1, 3))\n",
    "fig, axs = plt.subplots(1, 3, figsize=fig_size, constrained_layout=True)\n",
    "\n",
    "init_start_scene_dict = dict(scene_dict)\n",
    "init_start_scene_dict['particle']['center'] = deepcopy(particle_init_pos)\n",
    "bitmap_init = mi.util.convert_to_bitmap( mi.render(mi.load_dict(init_start_scene_dict), spp=16))\n",
    "axs[0].imshow(bitmap_init)\n",
    "axs[0].set_xticks([])\n",
    "axs[0].set_yticks([])\n",
    "axs[0].set_title('Start State')\n",
    "\n",
    "\n",
    "init_end_scene_dict = dict(scene_dict)\n",
    "init_end_scene_dict['particle']['center'] = deepcopy(phys_pred['pos'].cpu().numpy())\n",
    "bitmap_init = mi.util.convert_to_bitmap(mi.render(mi.load_dict(init_end_scene_dict), spp=16))\n",
    "axs[1].imshow(bitmap_init)\n",
    "axs[1].set_xticks([])\n",
    "axs[1].set_yticks([])\n",
    "axs[1].set_title('Initial End State')\n",
    "\n",
    "\n",
    "bitmap_target = mi.util.convert_to_bitmap(target_img)\n",
    "axs[2].imshow(bitmap_target)\n",
    "axs[2].set_xticks([])\n",
    "axs[2].set_yticks([])\n",
    "axs[2].set_title('Target End State')\n",
    "\n",
    "plt.show()\n",
    "#plt.savefig('fig_image_traj_states.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "train_iters = 30\n",
    "train_rate = 0.1\n",
    "train_save_interval = 15\n",
    "\n",
    "# physics\n",
    "phys_device = wp.get_cuda_devices()[0]\n",
    "phys_model, phys_states, phys_params, phys_pred = build_phys(phys_device, est_names=['vel'], pred_names=['pos'])\n",
    "phys_integrator = wp.sim.SemiImplicitIntegrator()\n",
    "phys_graph, phys_tape = capture_phys(phys_device, phys_model, phys_integrator, phys_states)\n",
    "phys_target = torch.tensor(target_pos, dtype=torch.float32, device=torch.device('cuda')).unsqueeze(0)\n",
    "\n",
    "# rendering\n",
    "vis_device = torch.device('cpu')\n",
    "vis_dict = dict(scene_dict)\n",
    "vis_dict['particle']['center'] = np.zeros(3)\n",
    "vis_scene = mi.load_dict(vis_dict)\n",
    "vis_spp = 4\n",
    "vis_params = mi.traverse(vis_scene)\n",
    "vis_obj_trafo = mi.Transform4f(vis_params['particle.to_world'])\n",
    "@dr.wrap_ad(source='torch', target='drjit')\n",
    "def render(trans):\n",
    "    trans = dr.unravel(mi.Point3f, trans)\n",
    "    trafo = mi.Transform4f.translate([trans.x, trans.y, trans.z])\n",
    "    vis_params['particle.to_world'] = trafo @ vis_obj_trafo\n",
    "    vis_params.update()\n",
    "    img = mi.render(vis_scene, vis_params, spp=vis_spp)\n",
    "    return img\n",
    "\n",
    "# optimization\n",
    "opt = torch.optim.Adam(list(phys_params.values()), lr=train_rate)\n",
    "loss = torch.nn.MSELoss(reduction='mean')\n",
    "\n",
    "# metrics\n",
    "trajs = []\n",
    "phys_errors = []\n",
    "vis_losses = []\n",
    "\n",
    "for i in range(train_iters+1):\n",
    "    # zero grads\n",
    "    opt.zero_grad(set_to_none=False)\n",
    "    phys_tape.zero()\n",
    "\n",
    "    # forward pass\n",
    "    wp.capture_launch(phys_graph)\n",
    "    vis_pred = render(phys_pred['pos'].to(vis_device))\n",
    "    vis_output = loss(vis_pred, target_img.torch())\n",
    "\n",
    "    if i < train_iters:\n",
    "        # backprop\n",
    "        vis_output.backward()\n",
    "        phys_tape.backward(grads={wp.from_torch(phys_pred['pos']) : wp.from_torch(phys_pred['pos'].grad)})\n",
    "        opt.step()\n",
    "        # don't want these to change\n",
    "        phys_params['vel'].data[0, 1:] = 0.0\n",
    "    \n",
    "\n",
    "    vis_losses.append(vis_output.cpu().detach().numpy())\n",
    "    phys_error = torch.linalg.norm(phys_pred['pos'] - phys_target).cpu().detach().numpy()\n",
    "    phys_errors.append(phys_error)\n",
    "    if i % train_save_interval == 0:\n",
    "        print(f\"iter_{i:02d}: img_loss={vis_losses[-1]:6f}, pose_error={phys_errors[-1]:6f} vel_x={phys_params['vel'][0,0]:.4f}\")\n",
    "        trajs.append(get_trajectory(phys_states))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_size = set_fig_size(subplots=(1, 3))\n",
    "fig, axs = plt.subplots(1, 3, figsize=fig_size, constrained_layout=True)\n",
    "\n",
    "################\n",
    "# Trajectories #\n",
    "################\n",
    "\n",
    "axs[0].set_title('Trajectories') \n",
    "for i, vel_traj in enumerate(trajs):\n",
    "    axs[0].plot(vel_traj[:, 0], vel_traj[:, 1], label=f'{i*train_save_interval}')\n",
    "axs[0].scatter(particle_init_pos[0], particle_init_pos[1], facecolors='none', edgecolors='black', s=50)\n",
    "axs[0].scatter(target_pos[0], target_pos[1], color='black', marker='+', s=50)\n",
    "axs[0].set_xlim([-2.1, 2.1])\n",
    "axs[0].set_ylim([0.8, 2.1])\n",
    "axs[0].set_xlabel('x')\n",
    "axs[0].set_ylabel('y')\n",
    "axs[0].legend(handlelength=0.5, loc='lower center', ncols=len(trajs)+2, columnspacing=0.5)\n",
    "\n",
    "###################\n",
    "# Losses / Errors #\n",
    "###################\n",
    "\n",
    "axs[1].plot(np.log(vis_losses))\n",
    "axs[1].set_xlim([-1, train_iters+1])\n",
    "axs[1].set_xticks(np.arange(0, train_iters+1, 10))\n",
    "axs[1].set_yticks(np.arange(-2, -8, -1))\n",
    "axs[1].set_ylim([-7, -2])\n",
    "axs[1].set_xlabel('Iteration')\n",
    "axs[1].set_ylabel('Log Image Loss')\n",
    "axs[1].set_title('Log Image Loss per Iteration')\n",
    "\n",
    "\n",
    "axs[2].plot(phys_errors)\n",
    "axs[2].set_xlim([-1, train_iters+1])\n",
    "axs[2].set_xticks(np.arange(0, train_iters+1, 10))\n",
    "axs[2].set_yticks(np.arange(0.0, 1.25, 0.4))\n",
    "axs[2].set_ylim([-0.05, 1.25])\n",
    "axs[2].set_xlabel('Iteration')\n",
    "axs[2].set_ylabel('Pose Error')\n",
    "axs[2].set_title('Pose Error per Iteration')\n",
    "\n",
    "plt.show()\n",
    "#plt.savefig('fig_image_traj_optim.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########\n",
    "# States #\n",
    "##########\n",
    "fig_size = set_fig_size(subplots=(1, 2))\n",
    "fig, axs = plt.subplots(1, 2, figsize=fig_size, constrained_layout=True)\n",
    "\n",
    "axs[0].imshow(mi.util.convert_to_bitmap(vis_pred))\n",
    "axs[0].set_xticks([])\n",
    "axs[0].set_yticks([])\n",
    "axs[0].set_title('Optimized End State')\n",
    "\n",
    "axs[1].imshow(bitmap_target)\n",
    "axs[1].set_xticks([])\n",
    "axs[1].set_yticks([])\n",
    "axs[1].set_title('Target End State')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "warp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
