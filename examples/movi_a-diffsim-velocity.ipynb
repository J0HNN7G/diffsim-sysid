{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-06 17:15:46.951616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warp 1.0.2 initialized:\n",
      "   CUDA Toolkit 11.5, Driver 11.4\n",
      "   Devices:\n",
      "     \"cpu\"      : \"x86_64\"\n",
      "     \"cuda:0\"   : \"NVIDIA GeForce GTX 1050 Ti with Max-Q Design\" (4 GiB, sm_61, mempool enabled)\n",
      "   Kernel cache:\n",
      "     /home/jonathan/.cache/warp/1.0.2\n",
      "Mitsuba 3 Variant: llvm_ad_rgb\n"
     ]
    }
   ],
   "source": [
    "# project\n",
    "import os\n",
    "import sys \n",
    "project_dir = os.path.join(os.path.expanduser('~'), 'git', 'diffsim-sysid')\n",
    "sys.path.insert(1, project_dir)\n",
    "# math\n",
    "import numpy as np\n",
    "# optim\n",
    "import torch\n",
    "# physics\n",
    "import warp as wp\n",
    "import warp.sim as wps\n",
    "# graphics\n",
    "from copy import deepcopy\n",
    "import drjit as dr\n",
    "import mitsuba as mi\n",
    "from mitsuba.scalar_rgb import Transform4f as mit\n",
    "# plots\n",
    "from matplotlib import pyplot as plt\n",
    "from src.mpl_utils import set_fig_size, set_mpl_format\n",
    "# sysid\n",
    "from src.sysid import SysId\n",
    "# config\n",
    "from src.config import cfg\n",
    "# dataset\n",
    "from src.sim import SIM_DURATION, SIM_DT, SIM_FPS, FRAME_DT, FRAME_STEPS, SIM_STEPS, SIM_SUBSTEPS, Sample, build_phys, run_phys, calc_density, get_density\n",
    "from src.dataset import load_train_data\n",
    "from src.warp_utils import render_usd\n",
    "\n",
    "# setup\n",
    "set_mpl_format()\n",
    "wp.init()\n",
    "mi.set_variant('llvm_ad_rgb')\n",
    "print(f'Mitsuba 3 Variant: {mi.variant()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA:\n",
      "  fps: 12\n",
      "  fpv: 24\n",
      "  height: 256\n",
      "  max_objs: 10\n",
      "  path: /home/jonathan/git/diffsim-sysid/data/sets/\n",
      "  set: movi_a\n",
      "  width: 256\n",
      "EVAL:\n",
      "  OUTPUT:\n",
      "    FN:\n",
      "      config: config.yaml\n",
      "      log: log.txt\n",
      "      pred: pred.csv\n",
      "    path: \n",
      "  PARAM:\n",
      "    DENSITY:\n",
      "      include: True\n",
      "SYS_ID:\n",
      "  OPTIM:\n",
      "    beta1: 0.9\n",
      "    beta2: 0.999\n",
      "    decay: 0.0\n",
      "    lr: 0.01\n",
      "    optim: adam\n",
      "  geom: True\n",
      "  iter: 4\n",
      "  rand: False\n",
      "  spp: 4\n",
      "  vis: False\n",
      "path: /home/jonathan/git/diffsim-sysid\n"
     ]
    }
   ],
   "source": [
    "# fill in your directory set up here\n",
    "config_fp = os.path.join(project_dir, f'cfg/templates/geom-movi_a.yaml')\n",
    "cfg.merge_from_file(config_fp)\n",
    "cfg.path = project_dir\n",
    "cfg.DATA.path = os.path.join(project_dir, 'data/sets/')\n",
    "print(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You use TensorFlow DType <dtype: 'float32'> in tfds.features This will soon be deprecated in favor of NumPy DTypes. In the meantime it was converted to float32.\n",
      "WARNING:absl:You use TensorFlow DType <dtype: 'int32'> in tfds.features This will soon be deprecated in favor of NumPy DTypes. In the meantime it was converted to int32.\n",
      "WARNING:absl:You use TensorFlow DType <dtype: 'uint16'> in tfds.features This will soon be deprecated in favor of NumPy DTypes. In the meantime it was converted to uint16.\n",
      "WARNING:absl:You use TensorFlow DType <dtype: 'uint8'> in tfds.features This will soon be deprecated in favor of NumPy DTypes. In the meantime it was converted to uint8.\n",
      "2024-04-06 17:15:51.727256: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-06 17:15:51.728636: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-06 17:15:51.729012: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-06 17:15:51.729482: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-06 17:15:51.729915: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-06 17:15:51.730194: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-06 17:15:51.730467: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-06 17:15:53.348752: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-06 17:15:53.349060: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-06 17:15:53.349317: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-06 17:15:53.349554: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3046 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050 Ti with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "WARNING:absl:`FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.\n",
      "WARNING:absl:`FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.\n",
      "WARNING:absl:`FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.\n",
      "WARNING:absl:`FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.\n",
      "WARNING:absl:`FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video: b'1680'\n"
     ]
    }
   ],
   "source": [
    "train_ds, ds_info = load_train_data(cfg)\n",
    "example = next(iter(train_ds))\n",
    "time_step = 20\n",
    "vid_id = example['metadata']['video_name']\n",
    "print(f'Video: {vid_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warp DeprecationWarning: Support for built-in functions called with non-Warp array types, such as lists, tuples, NumPy arrays, and others, will be dropped in the future. Use a Warp type such as `wp.vec`, `wp.mat`, `wp.quat`, or `wp.transform`.\n",
      "Module warp.sim.collide load on device 'cuda:0' took 135.81 ms\n",
      "Module warp.sim.integrator_euler load on device 'cuda:0' took 103.67 ms\n",
      "Module warp.sim.integrator load on device 'cuda:0' took 7.12 ms\n"
     ]
    }
   ],
   "source": [
    "sysid = SysId(cfg)\n",
    "target = Sample(cfg, example)\n",
    "start_time_step = 0\n",
    "final_time_step = 1\n",
    "\n",
    "# input\n",
    "sysid.set_sample(example)\n",
    "sysid.set_priors()\n",
    "\n",
    "# targets\n",
    "target_time_step_dict = target.get_render_timestep_dict(final_time_step)\n",
    "target_vis = mi.render(mi.load_dict(target_time_step_dict), spp=64).torch()\n",
    "target_geom = torch.tensor(target.body_q[final_time_step], requires_grad=False)\n",
    "target_vel = torch.tensor(target.body_qd[final_time_step], requires_grad=False)\n",
    "\n",
    "# training\n",
    "cfg.SYS_ID.iter = 10\n",
    "cfg.SYS_ID.lr = 1.0\n",
    "train_save_interval = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimized variables\n",
    "x_prior = np.zeros_like(target.body_qd[start_time_step])\n",
    "\n",
    "# physics\n",
    "phys_device = wp.get_cuda_devices()[0]\n",
    "phys_integrator = wps.SemiImplicitIntegrator()\n",
    "phys_model = build_phys(cfg, \n",
    "                        example,\n",
    "                        target.body_q[start_time_step],\n",
    "                        x_prior)\n",
    "phys_states = [phys_model.state(requires_grad=True) for _ in range(SIM_STEPS+1)]\n",
    "phys_tape = run_phys(phys_model, phys_states, phys_integrator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 481/481 [00:00<00:00, 502.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the USD stage file at `/home/jonathan/git/diffsim-sysid/examples/initial.usd`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "render_usd('initial.usd', phys_model, phys_states, SIM_DURATION, SIM_DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter_00: loss=65.678375, error=   nan\n",
      "tensor([[-1.0000,  1.0000,  1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000,  1.0000, -1.0000,  1.0000,  1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000,  1.0000,  1.0000, -1.0000, -1.0000],\n",
      "        [ 1.0000,  1.0000,  1.0000,  1.0000, -1.0000,  1.0000],\n",
      "        [-1.0000, -1.0000,  1.0000,  1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000],\n",
      "        [ 1.0000,  1.0000, -1.0000,  1.0000, -1.0000,  1.0000],\n",
      "        [    nan,     nan,     nan,     nan,     nan,     nan]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "iter_01: loss=   nan, error=   nan\n",
      "tensor([[nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan]], device='cuda:0', requires_grad=True)\n",
      "iter_02: loss=   nan, error=   nan\n",
      "tensor([[nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan]], device='cuda:0', requires_grad=True)\n",
      "iter_03: loss=   nan, error=   nan\n",
      "tensor([[nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan]], device='cuda:0', requires_grad=True)\n",
      "iter_04: loss=   nan, error=   nan\n",
      "tensor([[nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan]], device='cuda:0', requires_grad=True)\n",
      "iter_05: loss=   nan, error=   nan\n",
      "tensor([[nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan]], device='cuda:0', requires_grad=True)\n",
      "iter_06: loss=   nan, error=   nan\n",
      "tensor([[nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan]], device='cuda:0', requires_grad=True)\n",
      "iter_07: loss=   nan, error=   nan\n",
      "tensor([[nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan]], device='cuda:0', requires_grad=True)\n",
      "iter_08: loss=   nan, error=   nan\n",
      "tensor([[nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan]], device='cuda:0', requires_grad=True)\n",
      "iter_09: loss=   nan, error=   nan\n",
      "tensor([[nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan]], device='cuda:0', requires_grad=True)\n",
      "iter_10: loss=   nan, error=   nan\n",
      "tensor([[nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan]], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# optimized variables\n",
    "x_prior = np.zeros_like(target.body_qd[start_time_step])\n",
    "\n",
    "# physics\n",
    "phys_device = wp.get_cuda_devices()[0]\n",
    "phys_integrator = wps.SemiImplicitIntegrator()\n",
    "phys_model = build_phys(cfg, \n",
    "                        example,\n",
    "                        target.body_q[start_time_step],\n",
    "                        x_prior)\n",
    "phys_states = [phys_model.state(requires_grad=True) for _ in range(SIM_STEPS+1)]\n",
    "phys_tape = run_phys(phys_model, phys_states, phys_integrator)\n",
    "\n",
    "x = wp.to_torch(phys_states[0].body_qd)\n",
    "phys_pred = wp.to_torch(phys_states[-1].body_q)\n",
    "\n",
    "opt = torch.optim.Adam([x], lr=cfg.SYS_ID.lr)\n",
    "\n",
    "# optimization\n",
    "if cfg.SYS_ID.geom:\n",
    "    loss = torch.nn.MSELoss(reduction='sum')\n",
    "if cfg.SYS_ID.vis:\n",
    "    loss = torch.nn.MSELoss(reduction='mean')\n",
    "\n",
    "# metrics\n",
    "est_errors = [] \n",
    "losses = []\n",
    "\n",
    "for i in range(cfg.SYS_ID.iter+1):\n",
    "\n",
    "    opt.zero_grad(set_to_none=False)\n",
    "    phys_tape.zero()\n",
    "\n",
    "    # physics forward\n",
    "    phys_tape = run_phys(phys_model, phys_states, phys_integrator)\n",
    "\n",
    "    if cfg.SYS_ID.geom:\n",
    "        # loss\n",
    "        output = loss(phys_pred, target_geom.to('cuda'))\n",
    "    elif cfg.SYS_ID.vis:\n",
    "        pass\n",
    "        # render forward\n",
    "        #vis_pred = render(phys_pred.to(vis_device))\n",
    "        # loss\n",
    "        #output = loss(vis_pred, target_vis)\n",
    "\n",
    "    if i < cfg.SYS_ID.iter:\n",
    "        # backward\n",
    "        output.backward()\n",
    "\n",
    "        wp_phys_pred = wp.from_torch(phys_pred)\n",
    "        phys_tape.backward(grads={wp_phys_pred: wp_phys_pred.grad})\n",
    "        \n",
    "        # update\n",
    "        opt.step()\n",
    "\n",
    "        # restrict\n",
    "        # TODO\n",
    "\n",
    "    # garbage collection\n",
    "    #render_usd(f'iter_{i}.usd', phys_model, phys_states, SIM_DURATION, SIM_DT)\n",
    "    #phys_tape = None\n",
    "    #wp_phys_pred = None\n",
    "    \n",
    "    losses.append(output.cpu().detach().numpy())\n",
    "    est_error = torch.functional.F.mse_loss(x.cpu(), target_vel).detach().numpy()\n",
    "    est_errors.append(est_error) \n",
    "    if i % train_save_interval == 0:\n",
    "        print(f\"iter_{i:02d}: loss={losses[-1]:6f}, error={est_errors[-1]:6f}\")\n",
    "        print(f'{x}')\n",
    "        #print(f'{phys_pred.cpu().detach().numpy()}')\n",
    "\n",
    "# # prediction errors\n",
    "# # pred errors = TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.SYS_ID.OPTIM.lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "warp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
