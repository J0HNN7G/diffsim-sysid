{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-06 16:41:28.511911: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warp 1.0.2 initialized:\n",
      "   CUDA Toolkit 11.5, Driver 11.4\n",
      "   Devices:\n",
      "     \"cpu\"      : \"x86_64\"\n",
      "     \"cuda:0\"   : \"NVIDIA GeForce GTX 1050 Ti with Max-Q Design\" (4 GiB, sm_61, mempool enabled)\n",
      "   Kernel cache:\n",
      "     /home/jonathan/.cache/warp/1.0.2\n",
      "Mitsuba 3 Variant: llvm_ad_rgb\n"
     ]
    }
   ],
   "source": [
    "# project\n",
    "import os\n",
    "import sys \n",
    "project_dir = os.path.join(os.path.expanduser('~'), 'git', 'diffsim-sysid')\n",
    "sys.path.insert(1, project_dir)\n",
    "# math\n",
    "import numpy as np\n",
    "# optim\n",
    "import torch\n",
    "# physics\n",
    "import warp as wp\n",
    "import warp.sim as wps\n",
    "# graphics\n",
    "from copy import deepcopy\n",
    "import drjit as dr\n",
    "import mitsuba as mi\n",
    "from mitsuba.scalar_rgb import Transform4f as mit\n",
    "# plots\n",
    "from matplotlib import pyplot as plt\n",
    "from src.mpl_utils import set_fig_size, set_mpl_format\n",
    "# sysid\n",
    "from src.sysid import SysId\n",
    "# config\n",
    "from src.config import cfg\n",
    "# dataset\n",
    "from src.sim import SIM_DURATION, SIM_DT, SIM_FPS, FRAME_DT, FRAME_STEPS, SIM_STEPS, SIM_SUBSTEPS, Sample, build_phys, run_phys, calc_density, get_density\n",
    "from src.dataset import load_train_data\n",
    "from src.warp_utils import render_usd\n",
    "\n",
    "# setup\n",
    "set_mpl_format()\n",
    "wp.init()\n",
    "mi.set_variant('llvm_ad_rgb')\n",
    "print(f'Mitsuba 3 Variant: {mi.variant()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA:\n",
      "  fps: 12\n",
      "  fpv: 24\n",
      "  height: 256\n",
      "  max_objs: 10\n",
      "  path: /home/jonathan/git/diffsim-sysid/data/sets/\n",
      "  set: movi_a\n",
      "  width: 256\n",
      "EVAL:\n",
      "  OUTPUT:\n",
      "    FN:\n",
      "      config: config.yaml\n",
      "      log: log.txt\n",
      "      pred: pred.csv\n",
      "    path: \n",
      "  PARAM:\n",
      "    DENSITY:\n",
      "      include: True\n",
      "SYS_ID:\n",
      "  OPTIM:\n",
      "    beta1: 0.9\n",
      "    beta2: 0.999\n",
      "    decay: 0.0\n",
      "    lr: 0.01\n",
      "    optim: adam\n",
      "  geom: True\n",
      "  iter: 4\n",
      "  rand: False\n",
      "  spp: 4\n",
      "  vis: False\n",
      "path: /home/jonathan/git/diffsim-sysid\n"
     ]
    }
   ],
   "source": [
    "# fill in your directory set up here\n",
    "config_fp = os.path.join(project_dir, f'cfg/templates/geom-movi_a.yaml')\n",
    "cfg.merge_from_file(config_fp)\n",
    "cfg.path = project_dir\n",
    "cfg.DATA.path = os.path.join(project_dir, 'data/sets/')\n",
    "print(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You use TensorFlow DType <dtype: 'float32'> in tfds.features This will soon be deprecated in favor of NumPy DTypes. In the meantime it was converted to float32.\n",
      "WARNING:absl:You use TensorFlow DType <dtype: 'int32'> in tfds.features This will soon be deprecated in favor of NumPy DTypes. In the meantime it was converted to int32.\n",
      "WARNING:absl:You use TensorFlow DType <dtype: 'uint16'> in tfds.features This will soon be deprecated in favor of NumPy DTypes. In the meantime it was converted to uint16.\n",
      "WARNING:absl:You use TensorFlow DType <dtype: 'uint8'> in tfds.features This will soon be deprecated in favor of NumPy DTypes. In the meantime it was converted to uint8.\n",
      "2024-04-06 16:41:30.075155: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-06 16:41:30.076406: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-06 16:41:30.076715: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-06 16:41:30.077232: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-06 16:41:30.077857: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-06 16:41:30.078166: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-06 16:41:30.078430: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-06 16:41:31.498751: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-06 16:41:31.499015: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-06 16:41:31.499242: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-06 16:41:31.499449: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3046 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050 Ti with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "WARNING:absl:`FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.\n",
      "WARNING:absl:`FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.\n",
      "WARNING:absl:`FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.\n",
      "WARNING:absl:`FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.\n",
      "WARNING:absl:`FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video: b'1680'\n"
     ]
    }
   ],
   "source": [
    "train_ds, ds_info = load_train_data(cfg)\n",
    "example = next(iter(train_ds))\n",
    "time_step = 20\n",
    "vid_id = example['metadata']['video_name']\n",
    "print(f'Video: {vid_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warp DeprecationWarning: Support for built-in functions called with non-Warp array types, such as lists, tuples, NumPy arrays, and others, will be dropped in the future. Use a Warp type such as `wp.vec`, `wp.mat`, `wp.quat`, or `wp.transform`.\n",
      "Module warp.sim.collide load on device 'cuda:0' took 107.65 ms\n",
      "Module warp.sim.integrator_euler load on device 'cuda:0' took 80.75 ms\n",
      "Module warp.sim.integrator load on device 'cuda:0' took 5.25 ms\n"
     ]
    }
   ],
   "source": [
    "sysid = SysId(cfg)\n",
    "target = Sample(cfg, example)\n",
    "start_time_step = 0\n",
    "final_time_step = -1\n",
    "\n",
    "# input\n",
    "sysid.set_sample(example)\n",
    "sysid.set_priors()\n",
    "\n",
    "# targets\n",
    "target_time_step_dict = target.get_render_timestep_dict(final_time_step)\n",
    "target_vis = mi.render(mi.load_dict(target_time_step_dict), spp=64).torch()\n",
    "target_geom = torch.tensor(target.body_q[final_time_step], requires_grad=False)\n",
    "target_density = torch.tensor(get_density(example), requires_grad=False)\n",
    "\n",
    "# training\n",
    "cfg.SYS_ID.iter = 10\n",
    "cfg.SYS_ID.lr = 1.0\n",
    "train_save_interval = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param grad tensor([-1.1218e+04, -1.6433e+02,  2.0658e+06,  1.6809e+06, -4.4922e+03,\n",
      "        -4.1881e-01,  1.8908e+01,  4.2788e+02], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 481/481 [00:00<00:00, 610.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the USD stage file at `/home/jonathan/git/diffsim-sysid/examples/iter_0.usd`\n",
      "iter_00: loss=185.954834, error=0.715771\n",
      "tensor([1.1000, 1.1000, 2.7000, 2.7000, 1.1000, 1.8786, 2.7000, 2.7000])\n",
      "param grad tensor([-6.0765e+11,  2.8015e-03, -1.6808e+02,  1.0758e+04,  1.1271e+05,\n",
      "        -4.6950e+05,  1.9074e+04,         nan], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 481/481 [00:00<00:00, 648.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the USD stage file at `/home/jonathan/git/diffsim-sysid/examples/iter_1.usd`\n",
      "iter_01: loss=12.516238, error=   nan\n",
      "tensor([1.1000, 1.1001, 1.1000, 2.7000, 2.7000, 1.1000, 2.7000,    nan])\n",
      "param grad tensor([nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 481/481 [00:00<00:00, 595.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the USD stage file at `/home/jonathan/git/diffsim-sysid/examples/iter_2.usd`\n",
      "iter_02: loss=   nan, error=   nan\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "param grad tensor([nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 481/481 [00:00<00:00, 611.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the USD stage file at `/home/jonathan/git/diffsim-sysid/examples/iter_3.usd`\n",
      "iter_03: loss=   nan, error=   nan\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "param grad tensor([nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 481/481 [00:00<00:00, 619.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the USD stage file at `/home/jonathan/git/diffsim-sysid/examples/iter_4.usd`\n",
      "iter_04: loss=   nan, error=   nan\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "param grad tensor([nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 481/481 [00:00<00:00, 589.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the USD stage file at `/home/jonathan/git/diffsim-sysid/examples/iter_5.usd`\n",
      "iter_05: loss=   nan, error=   nan\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "param grad tensor([nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 481/481 [00:00<00:00, 521.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the USD stage file at `/home/jonathan/git/diffsim-sysid/examples/iter_6.usd`\n",
      "iter_06: loss=   nan, error=   nan\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "param grad tensor([nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 481/481 [00:00<00:00, 610.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the USD stage file at `/home/jonathan/git/diffsim-sysid/examples/iter_7.usd`\n",
      "iter_07: loss=   nan, error=   nan\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "param grad tensor([nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 481/481 [00:00<00:00, 570.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the USD stage file at `/home/jonathan/git/diffsim-sysid/examples/iter_8.usd`\n",
      "iter_08: loss=   nan, error=   nan\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "param grad tensor([nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 481/481 [00:00<00:00, 580.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the USD stage file at `/home/jonathan/git/diffsim-sysid/examples/iter_9.usd`\n",
      "iter_09: loss=   nan, error=   nan\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 481/481 [00:00<00:00, 559.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the USD stage file at `/home/jonathan/git/diffsim-sysid/examples/iter_10.usd`\n",
      "iter_10: loss=   nan, error=   nan\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# optimized variables\n",
    "pred_density = sysid.density_prior\n",
    "\n",
    "# physics\n",
    "phys_device = wp.get_cuda_devices()[0]\n",
    "phys_integrator = wps.SemiImplicitIntegrator()\n",
    "\n",
    "# optimization\n",
    "if cfg.SYS_ID.geom:\n",
    "    loss = torch.nn.MSELoss(reduction='sum')\n",
    "if cfg.SYS_ID.vis:\n",
    "    loss = torch.nn.MSELoss(reduction='mean')\n",
    "\n",
    "# metrics\n",
    "est_errors = [] \n",
    "losses = []\n",
    "\n",
    "for i in range(cfg.SYS_ID.iter+1):\n",
    "    # physics forward\n",
    "    phys_model = build_phys(cfg, example,\n",
    "                            target.body_q[start_time_step], \n",
    "                            target.body_qd[start_time_step],\n",
    "                            pred_density)\n",
    "    phys_states = [phys_model.state(requires_grad=True) for _ in range(SIM_STEPS+1)]\n",
    "    phys_tape = run_phys(phys_model, phys_states, phys_integrator)\n",
    "    phys_inv_mass = wp.to_torch(phys_model.body_inv_mass)\n",
    "    phys_pred = wp.to_torch(phys_states[-1].body_q)\n",
    "\n",
    "    opt = torch.optim.SGD([phys_inv_mass], lr=cfg.SYS_ID.OPTIM.lr)\n",
    "\n",
    "    if cfg.SYS_ID.geom:\n",
    "        # loss\n",
    "        output = loss(phys_pred, target_geom.to('cuda'))\n",
    "    elif cfg.SYS_ID.vis:\n",
    "        pass\n",
    "        # render forward\n",
    "        #vis_pred = render(phys_pred.to(vis_device))\n",
    "        # loss\n",
    "        #output = loss(vis_pred, target_vis)\n",
    "\n",
    "    if i < cfg.SYS_ID.iter:\n",
    "        # backward\n",
    "        output.backward()\n",
    "\n",
    "        wp_phys_pred = wp.from_torch(phys_pred)\n",
    "        phys_tape.backward(grads={wp_phys_pred: wp_phys_pred.grad})\n",
    "        print('param grad', phys_inv_mass.grad)\n",
    "\n",
    "\n",
    "        # update\n",
    "        #opt.step()\n",
    "\n",
    "        # restrict\n",
    "\n",
    "        # step\n",
    "        new_inv_mass = phys_inv_mass.cpu().detach().numpy() - cfg.SYS_ID.OPTIM.lr * phys_inv_mass.grad.cpu().detach().numpy()\n",
    "        np.clip(new_inv_mass, sysid.inv_mass_min.numpy(), sysid.inv_mass_max.numpy(), out=new_inv_mass)\n",
    "        #phys_inv_mass= torch.clamp(phys_inv_mass.to('cpu'), sysid.inv_mass_min, sysid.inv_mass_max).detach().numpy()\n",
    "        pred_density = torch.tensor(calc_density(new_inv_mass, example))\n",
    "        # phys_params.data = target_params.to('cuda').data\n",
    "\n",
    "    # zero\n",
    "    opt.zero_grad(set_to_none=False)\n",
    "    phys_tape.zero()\n",
    "\n",
    "    # garbage collection\n",
    "    render_usd(f'iter_{i}.usd', phys_model, phys_states, SIM_DURATION, SIM_DT)\n",
    "    phys_inv_mass = None\n",
    "    phys_model = None\n",
    "    phys_states = None\n",
    "    phys_tape = None\n",
    "    wp_phys_pred = None\n",
    "    \n",
    "    losses.append(output.cpu().detach().numpy())\n",
    "    est_error = torch.functional.F.mse_loss(pred_density, target_density).detach().numpy()\n",
    "    est_errors.append(est_error) \n",
    "    if i % train_save_interval == 0:\n",
    "        print(f\"iter_{i:02d}: loss={losses[-1]:6f}, error={est_errors[-1]:6f}\")\n",
    "        print(f'{pred_density}')\n",
    "        #print(f'{phys_pred.cpu().detach().numpy()}')\n",
    "\n",
    "# # prediction errors\n",
    "# # pred errors = TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.SYS_ID.OPTIM.lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "warp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
